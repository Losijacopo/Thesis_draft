Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Wei2004,
author = {Wei, Yichen},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/10.1.1.187.8155.pdf:pdf},
isbn = {0769521584},
number = {C},
title = {{Region-Based Progressive Stereo Matching Department of Computer Science , Hong Kong University of Science and Technology}},
volume = {00},
year = {2004}
}
@article{Zbontar2016,
abstract = {We present a method for extracting depth information from a rectified image pair. Our approach focuses on the first stage of many stereo algorithms: the matching cost computation. We approach the problem by learning a similarity measure on small image patches using a convolutional neural network. Training is carried out in a supervised manner by constructing a binary classification data set with examples of similar and dissimilar pairs of patches. We examine two network architectures for this task: one tuned for speed, the other for accuracy. The output of the convolutional neural network is used to initialize the stereo matching cost. A series of post-processing steps follow: cross-based cost aggregation, semiglobal matching, a left-right consistency check, subpixel enhancement, a median filter, and a bilateral filter. We evaluate our method on the KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that it outperforms other approaches on all three data sets.},
archivePrefix = {arXiv},
arxivId = {1510.05970},
author = {{\v{Z}}bontar, Jure and Lecun, Yann},
eprint = {1510.05970},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/15-535.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Convolutional neural networks,Matching cost,Similarity learning,Stereo,Supervised learning},
pages = {1--32},
title = {{Stereo matching by training a convolutional neural network to compare image patches}},
volume = {17},
year = {2016}
}
@article{Patil2013,
abstract = {This paper explains various cost aggregation methods used in stereo vision systems and does comparison between these methods to find out optimum method for a given cost and for a given set of resources. The paper also throws light on optimum method for implementation of stereo vision system on FPGA's and SOC's. The paper concludes with the fact that though methods like NCC and ZNCC offer higher accuracy but they are computationally heavy for embedding into real time systems. SAD and SSD are suitable choice for embedded systems. However applications requiring higher accuracy should use correlation based method.},
author = {Patil, Suyog and Nadar, Joseph Simon and Gada, Jimit and Motghare, Siddhartha and Nair, Sujath S},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Patil et al. - 2013 - Comparison of Various Stereo Vision Cost Aggregation Methods.pdf:pdf},
journal = {International Journal of Engineering and Innovative Technology},
number = {8},
pages = {222--226},
title = {{Comparison of Various Stereo Vision Cost Aggregation Methods}},
url = {http://www.ijeit.com/vol 2/Issue 8/IJEIT1412201302{\_}45.pdf},
volume = {2},
year = {2013}
}
@article{Birchfield1999,
abstract = {An algorithm to detect depth discontinuities from a stereo pair of images is presented. The algorithm matches individual pixels in corresponding scanline pairs, while allowing occluded pixels to remain unmatched, then propagates the information between scanlines by means of a fast postprocessor. The algorithm handles large untextured regions, uses a measure of pixel dissimilarity that is insensitive to image sampling, and prunes bad search nodes to increase the speed of dynamic programming. The computation is relatively fast, taking about 600 nanoseconds per pixel per disparity on a personal computer. Approximate disparity maps and precise depth discontinuities (along both horizontal and vertical boundaries) are shown for several stereo image pairs containing textured, untextured, fronto-parallel, and slanted objects in indoor and outdoor scenes.},
author = {Birchfield, Stan and Tomasi, Carlo},
doi = {10.1023/A:1008160311296},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Birchfield-Tomasi1999{\_}Article{\_}DepthDiscontinuitiesByPixel.pdf:pdf},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {depth discontinuities,dynamic programming,image sampling,stereo matching,untextured scenes},
number = {3},
pages = {269--293},
title = {{Depth discontinuities by pixel-to-pixel stereo}},
volume = {35},
year = {1999}
}
@article{Feng2006,
abstract = {Correlation is widely used as an effective similarity measure in matching tasks. However, traditional correlation based matching methods are limited to the short baseline case. In this paper we propose a new correlation based method for matching two images with large camera motion. Our method is based on the rotation and scale invariant normalized cross-correlation. Both the size and the orientation of the correlation windows are determined according to the characteristic scale and the dominant direction of the interest points. Experimental results on real images demonstrate that the new method is effective for matching image pairs with significant rotation and scale changes as well as other common imaging conditions. {\textcopyright} 2006 IEEE.},
author = {Feng, Zhao and Qingming, Huang and Wen, Gao},
doi = {10.1109/icassp.2006.1660446},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Feng, Qingming, Wen - 2006 - Image matching by normalized cross-correlation.pdf:pdf},
isbn = {142440469X},
issn = {15206149},
journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
number = {June 2006},
title = {{Image matching by normalized cross-correlation}},
volume = {2},
year = {2006}
}
@article{Shukla2006,
abstract = {Local feature detection and description have gained a lot of interest in recent years since photometric descriptors computed for in- terest regions have proven to be very successful in many applications. In this paper, we propose a novel interest region descriptor which combines the strengths of the well-known SIFT descriptor and the LBP texture operator. It is called the center-symmetric local binary pattern (CS-LBP) descriptor. This new descriptor has several advantages such as tolerance to illumination changes, robustness on flat image areas, and computa- tional efficiency. We evaluate our descriptor using a recently presented test protocol. Experimental results show that the CS-LBP descriptor outperforms the SIFT descriptor for most of the test cases, especially for images with severe illumination variations.},
author = {Shukla, Narendra Kumar and Rathi, Vivek and Chakka, Vijaykumar},
doi = {10.1007/11949619},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shukla, Rathi, Chakka - 2006 - Computer Vision, Graphics and Image Processing.pdf:pdf},
isbn = {978-3-540-68301-8},
journal = {Icvgip},
number = {June 2008},
pages = {894--905},
title = {{Computer Vision, Graphics and Image Processing}},
url = {http://dblp.uni-trier.de/db/conf/icvgip/icvgip2006.html{\#}ShuklaRC06},
volume = {4338},
year = {2006}
}
@article{Brice1970,
author = {Brice, Claude R and Fennema, Claude L and Journal, A I},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/a638144.pdf:pdf},
number = {April},
title = {{by Paper to be submitted for publication in Technical Note 17 The research reported here was supported by the Advanced under Contract F30602-69-C-0056 , and is continuing under Administration and the Advanced Research Projects Agency .}},
year = {1970}
}
@article{Hirschmuller2007,
abstract = {Stereo correspondence methods rely on matching costs for computing the similarity of image locations. In this paper we evaluate the insensitivity of different matching costs with respect to radiometric variations of the input images. We consider both pixel-based and window-based variants and measure their performance in the presence of global intensity changes (e.g., due to gain and exposure differences), local intensity changes (e.g., due to vignetting, non-Lambertian surfaces, and varying lighting), and noise. Using existing stereo datasets with ground-truth disparities as well as six new datasets taken under controlled changes of exposure and lighting, we evaluate the different costs with a local, a semi-global, and a global stereo method. {\textcopyright} 2007 IEEE.},
author = {Hirschm{\"{u}}ller, Heiko and Scharstein, Daniel},
doi = {10.1109/CVPR.2007.383248},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirschm{\"{u}}ller, Scharstein - 2007 - Evaluation of cost functions for stereo matching.pdf:pdf},
isbn = {1424411807},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
title = {{Evaluation of cost functions for stereo matching}},
year = {2007}
}
@article{Ilg2018a,
abstract = {Optical flow estimation can be formulated as an end-to-end supervised learning problem, which yields estimates with a superior accuracy-runtime tradeoff compared to alternative methodology. In this paper, we make such networks estimate their local uncertainty about the correctness of their prediction, which is vital information when building decisions on top of the estimations. For the first time we compare several strategies and techniques to estimate uncertainty in a large-scale computer vision task like optical flow estimation. Moreover, we introduce a new network architecture and loss function that enforce complementary hypotheses and provide uncertainty estimates efficiently with a single forward pass and without the need for sampling or ensembles. We demonstrate the quality of the uncertainty estimates, which is clearly above previous confidence measures on optical flow and allows for interactive frame rates.},
archivePrefix = {arXiv},
arxivId = {1802.07095},
author = {Ilg, Eddy and {\c{C}}i{\c{c}}ek, {\"{O}}zg{\"{u}}n and Galesso, Silvio and Klein, Aaron and Makansi, Osama and Hutter, Frank and Brox, Thomas},
doi = {10.1007/978-3-030-01234-2_40},
eprint = {1802.07095},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ilg et al. - 2018 - Uncertainty estimates and multi-hypotheses networks for optical flow.pdf:pdf},
isbn = {9783030012335},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Convolutional neural networks,Optical flow estimation,Uncertainty estimation},
pages = {677--693},
title = {{Uncertainty estimates and multi-hypotheses networks for optical flow}},
volume = {11211 LNCS},
year = {2018}
}
@article{Spangenberg2013,
abstract = {Automotive applications based on stereo vision require robust and fast matching algorithms, which makes semi-global matching (SGM) a popular method in this field. Typically the Census transform is used as a cost function, since it is advantageous for outdoor scenes. We propose an extension based on center-symmetric local binary patterns, which allows better efficiency and higher matching quality. Our second contribution exploits knowledge about the three-dimensional structure of the scene to selectively enforce the smoothness constraints of SGM. It is shown that information about surface normals can be easily integrated by weighing the paths according to the gradient of the disparity. The different approaches are evaluated on the KITTI benchmark, which provides real imagery with LIDAR ground truth. The results indicate improved performance compared to state-of-the-art SGM based algorithms. {\textcopyright} 2013 Springer-Verlag.},
author = {Spangenberg, Robert and Langner, Tobias and Rojas, Ra{\'{u}}l},
doi = {10.1007/978-3-642-40246-3_5},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spangenberg, Langner, Rojas - 2013 - Weighted semi-global matching and center-symmetric census transform for robust driver assistance.pdf:pdf},
isbn = {9783642402456},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {census transform,local binary pattern,matching costs,semi-global matching,stereo vision},
number = {PART 2},
pages = {34--41},
title = {{Weighted semi-global matching and center-symmetric census transform for robust driver assistance}},
volume = {8048 LNCS},
year = {2013}
}
@book{Wilson2013,
author = {Wilson, Richard and Hancock, Edwin and Eds, William Smith and Hutchison, David},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilson et al. - 2013 - Computer Analysis of Images and Patterns - Tracking for Quantifying Social Network of Drosophila Melanogaster.pdf:pdf},
isbn = {9783642402463},
number = {August},
pages = {362--369},
title = {{Computer Analysis of Images and Patterns - Tracking for Quantifying Social Network of Drosophila Melanogaster}},
year = {2013}
}
@article{Keselman2017,
author = {Keselman, Leonid and Grunnet-jepsen, Anders},
doi = {10.1109/CVPRW.2017.167},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Keselman{\_}Intel{\_}RealSense{\_}Stereoscopic{\_}CVPR{\_}2017{\_}paper.pdf:pdf},
number = {1},
pages = {1267--1276},
title = {{Stereoscopic Depth Cameras}},
year = {2017}
}
@article{Einecke2010,
abstract = {The computation of stereoscopic depth is an important field of computer vision. Although a large variety of algorithms has been developed, the traditional correlation-based versions of these algorithms are prevalent. This is mainly due to easy implementation and handling but also to the linear computational complexity, as compared to more elaborated algorithms based on diffusion processes, graph-cut or bilateral filtering. In this paper, we introduce a new two-stage matching cost for the traditional approach: the summed normalized cross-correlation (SNCC). This new cost function performs a normalized cross-correlation in the first stage and aggregates the correlation values in a second stage. We show that this new measure can be implemented efficiently and that it leads to a substantial improvement of the performance of the traditional stereo approach because it is less sensitive to high contrast outliers. {\textcopyright} 2010 IEEE.},
author = {Einecke, Nils and Eggert, Julian},
doi = {10.1109/DICTA.2010.49},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Einecke, Eggert - 2010 - A two-stage correlation method for stereoscopic depth estimation.pdf:pdf},
isbn = {9780769542713},
journal = {Proceedings - 2010 Digital Image Computing: Techniques and Applications, DICTA 2010},
keywords = {Cost function,Reduced fattening,Stereoscopic depth},
pages = {227--234},
title = {{A two-stage correlation method for stereoscopic depth estimation}},
year = {2010}
}
@article{Pang,
abstract = {Leveraging on the recent developments in convolutional neural networks (CNNs), matching dense correspondence from a stereo pair has been cast as a learning problem, with performance exceeding traditional approaches. However, it remains challenging to generate high-quality disparities for the inherently ill-posed regions. To tackle this problem, we propose a novel cascade CNN architecture composing of two stages. The first stage advances the recently proposed DispNet by equipping it with extra up-convolution modules, leading to disparity images with more details. The second stage explicitly rectifies the disparity initialized by the first stage; it couples with the first-stage and generates residual signals across multiple scales. The summation of the outputs from the two stages gives the final disparity. As opposed to directly learning the disparity at the second stage, we show that residual learning provides more effective refinement. Moreover, it also benefits the training of the overall cascade network. Experimentation shows that our cascade residual learning scheme provides state-of-the-art performance for matching stereo correspondence. By the time of the submission of this paper, our method ranks first in the KITTI 2015 stereo benchmark, surpassing the prior works by a noteworthy margin.},
author = {Pang, Jiahao and Sun, Wenxiu and Ren, Jimmy Sj and Yang, Chengxi and Yan, Qiong},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Pang{\_}Cascade{\_}Residual{\_}Learning{\_}ICCV{\_}2017{\_}paper.pdf:pdf},
pages = {887--895},
title = {{Cascade Residual Learning}},
url = {http://openaccess.thecvf.com/content{\_}ICCV{\_}2017{\_}workshops/papers/w17/Pang{\_}Cascade{\_}Residual{\_}Learning{\_}ICCV{\_}2017{\_}paper.pdf}
}
@article{Stein2004,
abstract = {This paper presents an approach for the estimation of visual motion over an image sequence in real-time. A new algorithm is proposed which solves the correspondence problem between two images in a very efficient way. The method uses the Census Transform as the representation of small image patches. These primitives are matched using a table based indexing scheme. We demonstrate the robustness of this technique on real-world image sequences of a road scenario captured from a vehicle based on-board camera. We focus on the computation of the optical flow. Our method runs in real-time on general purpose platforms and handles large displacements. {\textcopyright} Springer-Verlag 2004.},
author = {Stein, Fridtjof},
doi = {10.1007/978-3-540-28649-3_10},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stein - 2004 - Efficient computation of optical flow using the census transform.pdf:pdf},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {79--86},
title = {{Efficient computation of optical flow using the census transform}},
volume = {3175},
year = {2004}
}
@article{Loop1999,
abstract = {Image rectification is the process of applying a pair of 2 dimensional projective transforms, or homographies, to a pair of images whose epipolar geometry is known so that epipolar lines in the original images map to horizontally aligned lines in the transformed images. We propose a novel technique for image rectification based on geometrically well defined criteria such that image distortion due to rectification is minimized. This is achieved by decomposing each homography into a specialized projective transform, a similarity transform, followed by a shearing transform. The effect of image distortion at each stage is carefully considered.},
author = {Loop, Charles and Zhang, Zhengyou},
doi = {10.1109/cvpr.1999.786928},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Loop, Zhang - 1999 - Computing rectifying homographies for stereo vision.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {125--131},
title = {{Computing rectifying homographies for stereo vision}},
volume = {1},
year = {1999}
}
@article{Zach2006,
abstract = {In this work we propose a scanline optimization procedure for computational stereo using a linear smoothness cost model performed by programmable graphics hardware. The main idea for an efficient implementation of this dynamic programming approach is a recursive scheme to calculate the min-convolution in a manner suitable for the parallel stream computation model of graphics processing units. Since many image similarity functions can be efficiently calculated by modern graphics hardware, it is reasonable to address the final disparity extraction by graphics processors as well. Our timing results indicate that the proposed approach is beneficial for larger image resolutions and disparity ranges in particular. {\textcopyright} 2006 IEEE.},
author = {Zach, Christopher and Sormann, Mario and Karner, Konrad},
doi = {10.1109/3DPVT.2006.124},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/scanline{\_}optimization.pdf:pdf},
isbn = {0769528252},
journal = {Proceedings - Third International Symposium on 3D Data Processing, Visualization, and Transmission, 3DPVT 2006},
pages = {512--518},
title = {{Scanline optimization for stereo on graphics hardware}},
year = {2006}
}
@article{Kuzmin2017,
abstract = {We present a new deep learning-based approach for dense stereo matching. Compared to previous works, our approach does not use deep learning of pixel appearance descriptors, employing very fast classical matching scores instead. At the same time, our approach uses a deep convolutional network to predict the local parameters of cost volume aggregation process, which in this paper we implement using differentiable domain transform. By treating such transform as a recurrent neural network, we are able to train our whole system that includes cost volume computation, cost-volume aggregation (smoothing), and winner-takes-all disparity selection end-to-end. The resulting method is highly efficient at test time, while achieving good matching accuracy. On the KITTI 2012 and KITTI 2015 benchmark, it achieves a result of 5.08{\%} and 6.34{\%} error rate respectively while running at 29 frames per second rate on a modern GPU.},
archivePrefix = {arXiv},
arxivId = {1611.05689},
author = {Kuzmin, Andrey and Mikushin, Dmitry and Lempitsky, Victor},
doi = {10.1109/MLSP.2017.8168183},
eprint = {1611.05689},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuzmin, Mikushin, Lempitsky - 2017 - End-to-End learning of cost-volume aggregation for real-time dense stereo.pdf:pdf},
isbn = {9781509063413},
issn = {21610371},
journal = {IEEE International Workshop on Machine Learning for Signal Processing, MLSP},
keywords = {Convolutional neural network,Cost-volume aggregation,Edge-preserving filtering,Recurrent neural network,Stereo matching},
pages = {1--6},
title = {{End-to-End learning of cost-volume aggregation for real-time dense stereo}},
volume = {2017-Septe},
year = {2017}
}
@article{Scharstein2001,
abstract = {Stereo matching is one of the most active research areas in computer vision. While a large number of algorithms for stereo correspondence have been developed, relatively little work has been done on characterizing their performance. In this paper, we present a taxonomy of dense, two-frame stereo methods designed to assess the different components and design decisions made in individual stereo algorithms. Using this taxonomy, we compare existing stereo methods and present experiments evaluating the performance of many different variants. In order to establish a common software platform and a collection of data sets for easy evaluation, we have designed a stand-alone, flexible C++ implementation that enables the evaluation of individual components and that can be easily extended to include new algorithms. We have also produced several new multiframe stereo data sets with ground truth, and are making both the code and data sets available on the Web.},
author = {Scharstein, D. and Szeliski, R. and Zabih, R.},
doi = {10.1109/SMBV.2001.988771},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/10.1.1.23.6064.pdf:pdf},
isbn = {0769513271},
journal = {Proceedings - IEEE Workshop on Stereo and Multi-Baseline Vision, SMBV 2001},
number = {December},
pages = {131--140},
title = {{A taxonomy and evaluation of dense two-frame stereo correspondence algorithms}},
year = {2001}
}
@article{Sun2018,
author = {Sun, Jian and Li, Yin},
doi = {10.7551/mitpress/8579.003.0028},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/10.1.1.84.584.pdf:pdf},
journal = {Markov Random Fields for Vision and Image Processing},
title = {{Symmetric Stereo Matching for Occlusion Handling}},
year = {2018}
}
@article{Wang2008,
abstract = {This paper presents a new stereo matching algorithm based on inter-regional cooperative optimization. The proposed algorithm uses regions as matching primitives and defines the corresponding region energy functional for matching by utilizing the color Statistics of regions and the constraints on smoothness and occlusion between adjacent regions. In order to obtain a more reasonable disparity map, a cooperative optimization procedure has been employed to minimize the matching costs of all regions by introducing the cooperative and competitive mechanism between regions. Firstly, a color based segmentation method is used to segment the reference image into regions with homogeneous color. Secondly, a local window-based matching method is used to determine the initial disparity estimate of each image pixel. And then, a voting based plane fitting technique is applied to obtain the parameters of disparity plane corresponding to each image region. Finally, the disparity plane parameters of all regions are iteratively optimized by an inter-regional cooperative optimization procedure until a reasonable disparity map is obtained. The experimental Results on Middlebury test set and real stereo images indicate that the performance of our method is competitive with the best stereo matching algorithms and the disparity maps recovered are close to the ground truth data. {\textcopyright}2008 IEEE.},
author = {Wang, Zeng Fu and Zheng, Zhi Gang},
doi = {10.1109/CVPR.2008.4587456},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/CORegion.pdf:pdf},
isbn = {9781424422432},
journal = {26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR},
title = {{A region based stereo matching algorithm using cooperative optimization}},
year = {2008}
}
@article{Yoon2006,
abstract = {We present a new window-based method for correspondence search using varying support-weights. We adjust the support-weights of the pixels in a given support window based on color similarity and geometric proximity to reduce the image ambiguity. Our method outperforms other local methods on standard stereo benchmarks. {\textcopyright} 2006 IEEE.},
author = {Yoon, Kuk Jin and Kweon, In So},
doi = {10.1109/TPAMI.2006.70},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/10.1.1.892.8572.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {3D/stereo scene analysis,Stereo},
number = {4},
pages = {650--656},
title = {{Adaptive support-weight approach for correspondence search}},
volume = {28},
year = {2006}
}
@article{Haeusler2013,
abstract = {The design phase in the life cycle of a construction project contributes significantly to the performance of a project. The poor outcomes from the design phase in the construction project development process are considered as the major contributors to project delay, poor performance, and budget overrun. All of these affect the overall project performance. It is the aim of this study to innovate a design process model to improve the performance of design process where conventional design processes would not be effectively or efficiently applied. The adaptation of lean principles with the identification of wastes in design process and identification of enablers in design process are evaluated. The innovative design process model presented in this paper is developed based on the core enabler that can be used to eliminate the identified waste. There are 15 wastes identified and the set-based concurrent engineering (SBCE) is considered in the core enabler of the design process model.},
archivePrefix = {arXiv},
arxivId = {1604.05132},
author = {Haeusler, Ralf and Nair, Rahul and Kondermann, Daniel and Mostegel, Christian and Rumpler, Markus and Fraundorfer, Friedrich and Bischof, Horst and Park, Min Gyu and Yoon, Kuk Jin and {Md Yusof}, Ismawi Hj and An, Min and Barghi, Mahsa H. and Luo, Wenjie and Schwing, Alexander G and Chen, Zhuoyuan and Sun, Xun and Wang, Liang and Yu, Y and Huang, C},
doi = {10.1109/CVPR.2015.7298605},
eprint = {1604.05132},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Haeusler{\_}Ensemble{\_}Learning{\_}for{\_}2013{\_}CVPR{\_}paper.pdf:pdf;:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Park{\_}Leveraging{\_}Stereo{\_}Matching{\_}2015{\_}CVPR{\_}paper.pdf:pdf;:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Zagoruyko{\_}Learning{\_}to{\_}Compare{\_}2015{\_}CVPR{\_}paper.pdf:pdf;:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Chen{\_}A{\_}Deep{\_}Visual{\_}ICCV{\_}2015{\_}paper.pdf:pdf;:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Mostegel{\_}Using{\_}Self-Contradiction{\_}to{\_}CVPR{\_}2016{\_}paper.pdf:pdf;:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Luo{\_}Efficient{\_}Deep{\_}Learning{\_}CVPR{\_}2016{\_}paper.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Computational modeling,Data models,Design process,Enablers,Feature extraction,KITTI benchmark,Lean consideration,Machine learning,Middlebury data sets,Neural networks,Project life cycle,Training,Visualization,benchmarking,confidence measure,convolutional neural network,cross-validation results,data-driven matching cost,deep visual correspondence embedding model,embedding feature space,global stereo framework,ground truth disparities,image matching,image patches,labeled training set,neural nets,pixel dissimilarity measurement,random forest,stereo,stereo image processing,stereo images,stereo matching costs,visual similarity relationships},
number = {i},
pages = {885--894},
title = {{A Deep Visual Correspondence Embedding Model}},
url = {http://www.cs.toronto.edu/},
volume = {07-12-June},
year = {2015}
}
@article{Einecke2013,
abstract = {Accurate stereoscopic depth estimation, in particular of the road surface area, is one of several key technologies to improve Advanced Driver Assistance Systems (ADAS). One major problem is that the quality of the stereoscopic depth measurements of the road is often poor - which is mainly attributed to a lack of texture on the road surface. Especially for patch-matching stereo algorithms, the estimated depths look irregular and bumpy. In this paper, we show that the violation of the fronto-parallel assumption is the major reason for a bad depth estimation and not a low-contrast texture on the road surface. Since patch-matching or block-matching stereo inherently assumes a constant disparity within one patch, this is violated if the cameras are oriented almost parallel to the ground, which is typically the case in ADAS, and which leads to a strong distortion of the appearance between the two cameras. In order to tackle this problem, we propose a compensation of this distortion by applying a linear warp on one of the stereo images according to the expected disparity for the planar ground. This recovers the fronto-parallel assumption and results in a very good depth estimations of road surfaces. Our experiments on the KITTI stereo benchmark demonstrate the quantitative competitiveness of the approach, while retaining the speed and simplicity of block-matching stereo approaches. Furthermore, our experiments show that the approach is very robust, achieving results for the road surface that are significantly better than standard patch-matching stereo processing without warping for a wide range of warp parameter settings. {\textcopyright} 2013 IEEE.},
author = {Einecke, Nils and Eggert, Julian},
doi = {10.1109/IVS.2013.6629469},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Einecke, Eggert - 2013 - Stereo image warping for improved depth estimation of road surfaces.pdf:pdf},
isbn = {9781467327558},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
number = {Iv},
pages = {189--194},
title = {{Stereo image warping for improved depth estimation of road surfaces}},
year = {2013}
}
@article{Gastal2011,
abstract = {We present a new approach for performing high-quality edgepreserving filtering of images and videos in real time. Our solution is based on a transform that defines an isometry between curves on the 2D image manifold in 5D and the real line. This transform preserves the geodesic distance between points on these curves, adaptively warping the input signal so that 1D edge-preserving filtering can be efficiently performed in linear time. We demonstrate three realizations of 1D edge-preserving filters, show how to produce high-quality 2D edge-preserving filters by iterating 1D-filtering operations, and empirically analyze the convergence of this process. Our approach has several desirable features: the use of 1D operations leads to considerable speedups over existing techniques and potential memory savings; its computational cost is not affected by the choice of the filter parameters; and it is the first edge-preserving filter to work on color images at arbitrary scales in real time, without resorting to subsampling or quantization. We demonstrate the versatility of our domain transform and edge-preserving filters on several real-time image and video processing tasks including edgepreserving filtering, depth-of-field effects, stylization, recoloring, colorization, detail enhancement, and tone mapping. {\textcopyright} 2011 ACM.},
author = {Gastal, Eduardo S.L. and Oliveira, Manuel M.},
doi = {10.1145/1964921.1964964},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/1964921.1964964.pdf:pdf},
isbn = {9781450309431},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {Anisotropic diffusion,Bilateral filter,Domain transform,Edge-preserving filtering},
number = {4},
title = {{Domain transform for edge-aware image and video processing}},
volume = {30},
year = {2011}
}
@article{Zhang2009,
abstract = {We propose an area-based local stereo matching algorithm for accurate disparity estimation across all image regions. A well-known challenge to local stereo methods is to decide an appropriate support window for the pixel under consideration, adapting the window shape or the pixelwise support weight to the underlying scene structures. Our stereo method tackles this problem with two key contributions. First, for each anchor pixel an upright cross local support skeleton is adaptively constructed, with four varying arm lengths decided on color similarity and connectivity constraints. Second, given the local cross-decision results, we dynamically construct a shape-adaptive full support region on the fly, merging horizontal segments of the crosses in the vertical neighborhood. Approximating image structures accurately, the proposed method is among the best performing local stereo methods according to the benchmark Middlebury stereo evaluation. Additionally, it reduces memory consumption significantly thanks to our compact local cross representation. To accelerate matching cost aggregation performed in an arbitrarily shaped 2-D region, we also propose an orthogonal integral image technique, yielding a speedup factor of 5-15 over the straightforward integration. {\textcopyright} 2009 IEEE.},
author = {Zhang, Ke and Lu, Jiangbo and Lafruit, Gauthier},
doi = {10.1109/TCSVT.2009.2020478},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Lu, Lafruit - 2009 - Cross-based local stereo matching using orthogonal integral images.pdf:pdf},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Cross-based region construction,Orthogonal integral images,Shape adaptive approximation,Stereo matching},
number = {7},
pages = {1073--1079},
title = {{Cross-based local stereo matching using orthogonal integral images}},
volume = {19},
year = {2009}
}
@article{Banz2010,
abstract = {This paper describes a new architecture and the corresponding implementation of a stereo vision system that covers the entire stereo vision process including noise reduction, rectification, disparity estimation, and visualization. Dense disparity estimation is performed using the non-parametric rank transform and semi-global matching (SGM), which is among the top performing stereo matching methods and outperforms locally-based methods in terms of quality of disparity maps and robustness under difficult imaging conditions. Stream-based processing of the SGM despite its non-scan-aligned, complex data dependencies is achieved by a scalable, systolic-array-based architecture. This architecture fulfills the demands of real-world applications regarding frame rate, depth resolution and low resource usage. The architecture is based on a novel two-dimensional parallelization concept for the SGM. An FPGA implementation on a Xilinx Virtex-5 generates disparity maps of VGA images (640x480 pixel) with a 128 pixel disparity range under real-time conditions (30 fps) at a clock frequency as low as 39 MHz. {\textcopyright}2010 IEEE.},
author = {Banz, Christian and Hesselbarth, Sebastian and Flatt, Holger and Blume, Holger and Pirsch, Peter},
doi = {10.1109/ICSAMOS.2010.5642077},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/fpga{\_}impl{\_}sgm.pdf:pdf},
isbn = {9781424479382},
journal = {Proceedings - 2010 International Conference on Embedded Computer Systems: Architectures, Modeling and Simulation, IC-SAMOS 2010},
pages = {93--101},
title = {{Real-time stereo vision system using semi-global matching disparity estimation: Architecture and FPGA-implementation}},
year = {2010}
}
@book{Zelinsky2009,
abstract = {With Early Release ebooks, you get books in their earliest form—the author's raw and unedited content as he or she writes—so you can take advantage of these technologies long before the official release of these titles. You'll also receive updates when significant changes are made, new chapters as they're written, and the final...},
author = {Zelinsky, Alex},
booktitle = {IEEE Robotics {\&} Automation Magazine},
doi = {10.1109/mra.2009.933612},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Learning{\_}OpenCV.pdf:pdf},
isbn = {9780596516130},
issn = {1070-9932},
number = {3},
pages = {100--100},
title = {{Learning OpenCV---Computer Vision with the OpenCV Library (Bradski, G.R. et al.; 2008)[On the Shelf]}},
volume = {16},
year = {2009}
}
@article{Seki2016,
abstract = {In this paper, we propose a novel method to predict the correctness of stereo correspondences, which we call confidence, and a confidence fusion method for dense disparity estimation. The input of our method consists in a two channels local window (disparity patch) which is designed by taking into account ideas of conventional confidence features. 1st channel is coming from the idea that neighboring pixels which have consistent disparities are more likely to be correct matching. In 2nd channel, a disparity from another image is considered such that the matches from left to right image should be consistent with those from right to left. The disparity patches are used as inputs of Convolutional Neural Networks so that the features and classifiers are simultaneously trained unlike what is done by existing methods. Moreover, the confidence is incorporated into Semi-Global Matching(SGM) by adjusting its parameters directly. We show the prominent performance of both confidence prediction and dense disparity estimation on KITTI datasets which are real world scenery.},
author = {Seki, Akihito and Pollefeys, Marc},
doi = {10.5244/C.30.23},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Seki, Pollefeys - 2016 - Patch based confidence prediction for dense disparity map.pdf:pdf},
journal = {British Machine Vision Conference 2016, BMVC 2016},
number = {c},
pages = {23.1--23.13},
title = {{Patch based confidence prediction for dense disparity map}},
volume = {2016-Septe},
year = {2016}
}
@article{Hirschmuller2012,
author = {Hirschm{\"{u}}ller, Heiko},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/02{\_}hirschmueller{\_}keynote{\_}sgm.pdf:pdf},
pages = {1--31},
title = {{Semi-Global Matching Introduction Semi-Global Matching}},
year = {2012}
}
@article{Hirschmuller2002a,
abstract = {This paper describes a real-time stereo vision system that is required to support high-level object based tasks in a tele-operated environment. Stereo vision is computationally expensive, due to having to find corresponding pixels. Correlation is a fast, standard way to solve the correspondence problem. This paper analyses the behaviour of correlation based stereo to find ways to improve its quality while maintaining its real-time suitability. Three methods are suggested. Two of them aim to improve the disparity image especially at depth discontinuities, while one targets the identification of possible errors in general. Results are given on real stereo images with ground truth. A comparison with five standard correlation methods is provided. All proposed algorithms are described in detail and performance issues and optimisation are discussed. Finally, performance results of individual parts of the stereo algorithm are shown, including rectification, filtering and correlation using all proposed methods. The implemented system shows that errors of simple stereo correlation, especially in object border regions, can be reduced in real-time using non-specialised computer hardware. {\textcopyright} 2002 Kluwer Academic Publishers.},
author = {Hirschm{\"{u}}ller, Heiko and Innocent, Peter R. and Garibaldi, Jon},
doi = {10.1023/A:1014554110407},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Real-time{\_}correlation-based{\_}stereo{\_}visio.pdf:pdf},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Correlation problems,Multiple correlation windows,Object border correction,Real-time,Stereo vision},
number = {1-3},
pages = {229--246},
title = {{Real-time correlation-based stereo vision with reduced border errors}},
volume = {47},
year = {2002}
}
@article{Hirschmuller2006,
abstract = {This paper considers the use of stereo vision in structured environments. Sharp discontinuities and large untextured areas must be anticipated, but complex or natural shapes of objects and fine structures should be handled as well. Additionally, radiometric differences of input images often occur in practice. Finally, computation time is an issue for handling large or many images in acceptable time. The Semi-Global Matching method is chosen as it fulfills already many of the requirements. Remaining problems in structured environments are carefully analyzed and two novel extensions suggested. Firstly, intensity consistent disparity selection is proposed for handling untextured areas. Secondly, discontinuity preserving interpolation is suggested for filling holes in the disparity images that are caused by some filters. It is shown that the performance of the new method on test images with ground truth is comparable to the currently best stereo methods, but the complexity and runtime is much lower. {\textcopyright} 2006 IEEE.},
author = {Hirschm{\"{u}}ller, Heiko},
doi = {10.1109/CVPR.2006.294},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/refined{\_}sgm.pdf:pdf},
isbn = {0769525970},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2386--2393},
title = {{Stereo vision in structured environments by consistent semi-global matching}},
volume = {2},
year = {2006}
}
@article{Hirschmuller2002,
abstract = {Since its original publication, the Semi-Global Matching (SGM) technique has been re-implemented by many researchers and companies. The method offers a very good trade off between runtime and accuracy, especially at object borders and fine structures. It is also robust against radiometric differences and not sensitive to the choice of parameters. Therefore, it is well suited for solving practical problems. The applications reach from remote sensing, like deriving digital surface models from aerial and satellite images, to robotics and driver assistance systems. This paper motivates and explains the method, shows current developments as well as examples from various applications.},
author = {Hirschm{\"{u}}ller, Heiko},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/general{\_}sgm.pdf:pdf},
number = {Figure 1},
pages = {173--184},
title = {{Semi-Global Matching – Motivation, Developments and Applications}},
year = {2002}
}
@article{Poggi2016,
abstract = {Stereo vision is a popular technique to infer depth from two or more images. In this field, confidence measures, typically obtained from the analysis of the cost volume, aim at detecting uncertain disparity assignments. As recently proved, multiple confidence measures combined with hand-crafted features extracted from the cost volume can be used also for other purposes and in particular to improve the overall disparity accuracy leveraging on machine learning techniques. In this paper, starting from the observation that recurrent local patterns occurring in the disparity maps can tell a correct assignment from a wrong one, we follow a completely different methodology to infer a novel confidence measure from scratch. Specifically, leveraging on Convolutional Neural Networks, we pose the confidence formulation as a regression problem by analyzing the disparity map provided by a stereo vision system. Once trained on a subset of the KITTI 2012 dataset with the disparity maps provided by the simple block-matching algorithm, our confidence measure outperforms state-of-the-art with two datasets (KITTI 2015 and Middlebury 2014) as well as with two stereo algorithms. The experimental evaluation reported clearly highlights that our approach is capable to better generalize its behavior in different circumstances with respect to state-of-the-art. Finally, not being based on cost volume analysis, our proposal is also potentially suited for out-of-the-box depth generation devices which usually do not expose the cues required by top-performing approaches.},
author = {Poggi, Matteo and Mattoccia, Stefano},
doi = {10.5244/C.30.46},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/BMVC2016.pdf:pdf},
journal = {British Machine Vision Conference 2016, BMVC 2016},
number = {Cv},
pages = {46.1--46.13},
title = {{Learning from scratch a confidence measure}},
volume = {2016-Septe},
year = {2016}
}
@article{DiazGomez2007,
abstract = {The objective of this work was to evaluate the inclusion of a concentrate of soy protein and two energy sources as milk substitutes on productive performance of Nubian kids from birth to weaning, managed at the Goat Unit of the Faculty of Agronomy, Universidad Aut{\'{o}}noma de San Luis Potos{\'{i}}, M{\'{e}}xico. Sixty eight kids (35 females and 33 males) were randomly assigned to the treatments: T1: lactic protein + cow lard, T2: 20.0{\%} of concentrate of soy protein + cow lard, T3: 40.0{\%} of concentrate of soy protein + cow lard, T4: lactic protein + pork lard, T5: 20.0{\%} concentrate of soy protein + pork lard and, T 6: 40.0{\%} of concentrate of soy protein + pork lard. The concentrate of soy protein did not affect (P{\textgreater}0.05) neither the consumption of liquid diet nor average daily weight gain, but it affected (P{\textless}0.05) consumption of the starting concentrate (95; 95, and 97 g d-1 animal-1). The energy sources did not affect (P{\textgreater}0.05) neither consumption of the liquid diet nor average daily weight gain, but they affected (P{\textless}0.05) consumption of the starting concentrate (97 vs 95 g d-1 animal-1). Sex of kid did not affect (P{\textgreater}0.05) neither consumption of the milk substitute nor average daily weight gain, but it affected (P{\textless}0.05) consumption of the starting concentrate (100 vs 92 g d-1 animal-1 for males and females, respectively). The experimental period (weeks) affected (P{\textless}0.05) all variables. The levels of the concentrate of soy protein, energy sources, and sex of kids did not affect (P{\textgreater}0.05) feed conversion based on milk total solids. There were some significant interactions (P{\textless}0.05) on consumption of the milk substitute and starting concentrate. It is concluded that it is possible to raise kids with milk substitutes prepared with a concentrate of soy protein, cow and/or pork lard.},
author = {{D{\'{i}}az G{\'{o}}mez}, Marta Ol{\'{i}}via and {Ochoa Cordero}, Manuel Antonio and {Torres Hern{\'{a}}ndez}, Glafiro and {Bisett Mandeville}, Peter and {Urrutia Morales}, Jorge and {De Jes{\'{u}}s Mor{\'{o}}n Cedillo}, Felipe},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/10.1.1.219.3390.pdf:pdf},
issn = {07982259},
journal = {Revista Cientifica de la Facultad de Ciencias Veterinarias de la Universidad del Zulia},
keywords = {Concentrate of soy protein,Cow lard and/or pork,Kids,Milk substitute,Starting concentrate},
number = {6},
pages = {597--605},
title = {{Efectos de la inclusi{\'{o}}n de un concentrado de prote{\'{i}}na de soya y dos fuentes de energ{\'{i}}a en el substituto de leche en el comportamiento productivo de cabritos nubios}},
volume = {17},
year = {2007}
}
@article{Szeliski2011,
abstract = {As humans, we perceive the three-dimensional structure of the world around us with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem, and what is the current state of the art?Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging and fun consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos.More than just a source of "recipes", this text/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting this process to produce the best possible descriptions of a scene. Exercises are presented throughout the book, with a heavy emphasis on testing algorithms.Suitable for either an undergraduate or a graduate-level course in computer vision, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries.Dr. Richard Szeliski has over twenty years' experience in computer vision research, most notably at Digital Equipment Corporation and Microsoft.},
author = {Szeliski, Richard},
doi = {10.5860/choice.48-5140},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Computer{\_}Vision{\_}Algorithms{\_}and{\_}Applicati.pdf:pdf},
issn = {0009-4978},
journal = {Choice Reviews Online},
number = {09},
pages = {48--5140--48--5140},
title = {{Computer vision: algorithms and applications}},
volume = {48},
year = {2011}
}
@article{Park2015,
abstract = {We propose a new approach to associate supervised learning-based confidence prediction with the stereo matching problem. First of all, we analyze the characteristics of various confidence measures in the regression forest framework to select effective confidence measures using training data. We then train regression forests again to predict the correctness (confidence) of a match by using selected confidence measures. In addition, we present a confidence-based matching cost modulation scheme based on the predicted correctness for improving the robustness and accuracy of various stereo matching algorithms. We apply the proposed scheme to the semi-global matching algorithm to make it robust under unexpected difficulties that can occur in outdoor environments. We verify the proposed confidence measure selection and cost modulation methods through extensive experimentation with various aspects using KITTI and challenging outdoor datasets.},
author = {Park, Min Gyu and Yoon, Kuk Jin},
doi = {10.1109/CVPR.2015.7298605},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Park{\_}Leveraging{\_}Stereo{\_}Matching{\_}2015{\_}CVPR{\_}paper.pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {101--109},
title = {{Leveraging stereo matching with learning-based confidence measures}},
volume = {07-12-June},
year = {2015}
}
@article{Mori2004,
abstract = {The goal of this work is to take an image such as the one in Figure 1(a), detect a human figure, and localize his joints and limbs (b) along with their associated pixel masks (c). In this work we attempt to tackle this problem in a general setting. The dataset we use is a collection of sports news photographs of baseball players, varying dramatically in pose and clothing. The approach that we take is to use segmentation to guide our recognition algorithm to salient bits of the image. We use this segmentation approach to build limb and torso detectors, the outputs of which are assembled into human figures. We present quantitative results on torso localization, in addition to shortlisted full body configurations.},
author = {Mori, Greg and Ren, Xiaofeng and Efros, Alexei A. and Malik, Jitendra},
doi = {10.1109/cvpr.2004.1315182},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/MoriMalik.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
title = {{Recovering human body configurations: Combining segmentation and recognition}},
volume = {2},
year = {2004}
}
@article{Egnal2000,
abstract = {Traditional stereo systems often falter over changes in lighting between their two views. Unfortunately, such changes often occur when using stereo with a wide baseline or between images from different spectra. In this paper, we propose a new dense stereo correspondence similarity metric, mutual information, which has the potential to overcome such adverse conditions. We explore the strengths and weaknesses of this metric, both quantitatively and qualitatively, under a variety of conditions. Throughout the exploration, we compare mutual information to a more traditional cross-correlation stereo system. We show that mutual information performs under conditions in which traditional dense stereo fails.},
author = {Egnal, Geoffrey},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/fulltext.pdf:pdf},
journal = {Technical Reports, Departement of Computer {\&} Information Science, University of Pennsylvania},
number = {MS-CIS-00-20},
title = {{Mutual Information as a Stereo Correspondence Measure}},
url = {http://repository.upenn.edu/cis{\_}reports/113/},
year = {2000}
}
@article{Ilg2018,
abstract = {Occlusions play an important role in disparity and optical flow estimation, since matching costs are not available in occluded areas and occlusions indicate depth or motion boundaries. Moreover, occlusions are relevant for motion segmentation and scene flow estimation. In this paper, we present an efficient learning-based approach to estimate occlusion areas jointly with disparities or optical flow. The estimated occlusions and motion boundaries clearly improve over the state-of-the-art. Moreover, we present networks with state-of-the-art performance on the popular KITTI benchmark and good generic performance. Making use of the estimated occlusions, we also show improved results on motion segmentation and scene flow estimation.},
archivePrefix = {arXiv},
arxivId = {1808.01838},
author = {Ilg, Eddy and Saikia, Tonmoy and Keuper, Margret and Brox, Thomas},
doi = {10.1007/978-3-030-01258-8_38},
eprint = {1808.01838},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ilg et al. - 2018 - Occlusions, Motion and depth boundaries with a generic network for disparity, optical flow or scene flow estimation.pdf:pdf},
isbn = {9783030012571},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {626--643},
title = {{Occlusions, Motion and depth boundaries with a generic network for disparity, optical flow or scene flow estimation}},
volume = {11216 LNCS},
year = {2018}
}
@article{Iwasokun2014,
abstract = {Image processing is faced with a number of challenges ranging from unequal resolutions, format variations, non uniform illuminations, distortions and noise. It is also affected by orientation and contrast differences. In view of these challenges, most digital image processing applications or devices employ enhancement procedure prior to the use of the captured image for intended purposes. This paper reports on the review of some of the existing digital image enhancement methods with emphasis on methodologies, strengths, limitations and application areas. The specific application of some of these methods by different authors is also presented.},
author = {Iwasokun, Gabriel},
doi = {10.9734/bjmcs/2014/10332},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Image{\_}Enhancement{\_}Methods{\_}A{\_}Review.pdf:pdf},
journal = {British Journal of Mathematics {\&} Computer Science},
number = {16},
pages = {2251--2277},
title = {{Image Enhancement Methods: A Review}},
volume = {4},
year = {2014}
}
@article{Felzenszwalb2006,
abstract = {Markov random field models provide a robust and unified framework for early vision problems such as stereo and image restoration. Inference algorithms based on graph cuts and belief propagation have been found to yield accurate results but despite recent advances are often too slow for practical use. In this paper we present some algorithmic techniques that substantially improve the running time of the loopy belief propagation approach. One of the techniques reduces the complexity of the inference algorithm to be linear rather than quadratic in the number of possible labels for each pixel which is important for problems such as image restoration that have a large label set. Another technique speeds up and reduces the memory requirements of belief propagation on grid graphs. A third technique is a multi-grid method that makes it possible to obtain good results with a small fixed number of message passing iterations independent of the size of the input images. Taken together these techniques speed up the standard algorithm by several orders of magnitude. In practice we obtain results that are as accurate as those of other global methods (e.g. using the Middlebury stereo benchmark) while being nearly as fast as purely local methods. {\textcopyright} 2006 Springer Science + Business Media, LLC.},
author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
doi = {10.1007/s11263-006-7899-4},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Felzenszwalb, Huttenlocher - 2006 - Efficient belief propagation for early vision.pdf:pdf},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Belief propagation,Efficient algorithms,Image restoration,Markov random fields,Stereo},
number = {1},
pages = {41--54},
title = {{Efficient belief propagation for early vision}},
volume = {70},
year = {2006}
}
@article{Gerig2012,
author = {Gerig, Guido},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gerig - 2012 - Image Rectification (Stereo).pdf:pdf},
title = {{Image Rectification (Stereo)}},
year = {2012}
}
@article{Chen2013,
abstract = {The semi-global matching algorithm (SGM) aiming for producing highly dense 3-D point cloud is based on exploring mutual information on a pixel-wise basis. Multi-directional 1-D smoothing constraint is applied to approximate what can be achieved by global stereo matching. The central idea of employing the smoothing constraint is to ease the ambiguity as well as to reduce wrong matches. For that, the purpose of this study is to characterize the smoothing constraint applied in SGM and to tune the terms of the constraint function with respect to the image content so that the smoothing effect can be better obtained and the matching quality can be improved consequently.},
author = {Chen, Yu Lin and Jaw, Jen Jer},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/cost{\_}aggregation{\_}evaluation.pdf:pdf},
isbn = {9781629939100},
journal = {34th Asian Conference on Remote Sensing 2013, ACRS 2013},
keywords = {Mutual information,Penalty function,Semi-global matching,Stereo matching},
number = {September},
pages = {1112--1117},
title = {{Optimization of penalty functions for semi-global matching cost aggregation}},
volume = {2},
year = {2013}
}
@article{Mayer2016,
abstract = {Recent work has shown that optical flow estimation can be formulated as a supervised learning task and can be successfully solved with convolutional networks. Training of the so-called FlowNet was enabled by a large synthetically generated dataset. The present paper extends the concept of optical flow estimation via convolutional networks to disparity and scene flow estimation. To this end, we propose three synthetic stereo video datasets with sufficient realism, variation, and size to successfully train large networks. Our datasets are the first large-scale datasets to enable training and evaluation of scene flow methods. Besides the datasets, we present a convolutional network for real-time disparity estimation that provides state-of-the-art results. By combining a flow and disparity estimation network and training it jointly, we demonstrate the first scene flow estimation with a convolutional network.},
archivePrefix = {arXiv},
arxivId = {1512.02134},
author = {Mayer, Nikolaus and Ilg, Eddy and Hausser, Philip and Fischer, Philipp and Cremers, Daniel and Dosovitskiy, Alexey and Brox, Thomas},
doi = {10.1109/CVPR.2016.438},
eprint = {1512.02134},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mayer et al. - 2016 - A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {4040--4048},
title = {{A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation}},
volume = {2016-Decem},
year = {2016}
}
@article{MdYusof2015,
abstract = {The design phase in the life cycle of a construction project contributes significantly to the performance of a project. The poor outcomes from the design phase in the construction project development process are considered as the major contributors to project delay, poor performance, and budget overrun. All of these affect the overall project performance. It is the aim of this study to innovate a design process model to improve the performance of design process where conventional design processes would not be effectively or efficiently applied. The adaptation of lean principles with the identification of wastes in design process and identification of enablers in design process are evaluated. The innovative design process model presented in this paper is developed based on the core enabler that can be used to eliminate the identified waste. There are 15 wastes identified and the set-based concurrent engineering (SBCE) is considered in the core enabler of the design process model.},
author = {{Md Yusof}, Ismawi Hj and An, Min and Barghi, Mahsa H.},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Zagoruyko{\_}Learning{\_}to{\_}Compare{\_}2015{\_}CVPR{\_}paper.pdf:pdf},
isbn = {9780955239090},
journal = {Proceedings of the 31st Annual Association of Researchers in Construction Management Conference, ARCOM 2015},
keywords = {Design process,Enablers,Lean consideration,Project life cycle},
number = {i},
pages = {885--894},
title = {{Integration of lean construction considerations into design process of construction projects}},
year = {2015}
}
@article{Pham2013,
abstract = {Binocular stereo matching is one of the most important algorithms in the field of computer vision. Adaptive support-weight approaches, the current state-of-the-art local methods, produce results comparable to those generated by global methods. However, excessive time consumption is the main problem of these algorithms since the computational complexity is proportionally related to the support window size. In this paper, we present a novel cost aggregation method inspired by domain transformation, a recently proposed dimensionality reduction technique. This transformation enables the aggregation of 2-D cost data to be performed using a sequence of 1-D filters, which lowers computation and memory costs compared to conventional 2-D filters. Experiments show that the proposed method outperforms the state-of-the-art local methods in terms of computational performance, since its computational complexity is independent of the input parameters. Furthermore, according to the experimental results with the Middlebury dataset and realworld images, our algorithm is currently one of the most accurate and efficient local algorithms. {\textcopyright} 2012 IEEE.},
author = {Pham, Cuong Cao and Jeon, Jae Wook},
doi = {10.1109/TCSVT.2012.2223794},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/10.1.1.352.6312.pdf:pdf},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Domain transformation,Local stereo matching.,Terms-Cost aggregation},
number = {7},
pages = {1119--1130},
title = {{Domain transformation-based efficient cost aggregation for local stereo matching}},
volume = {23},
year = {2013}
}
@article{Hermann2013,
abstract = {Semi-global matching (SGM) is a technique of choice for dense stereo estimation in current industrial driver-assistance systems due to its real-time processing capability and its convincing performance. In this paper we introduce iSGM as a new cost integration concept for semi-global matching. In iSGM, accumulated costs are iteratively evaluated and intermediate disparity results serve as input to generate semi-global distance maps. This novel data structure supports fast analysis of spatial disparity information and allows for reliable search space reduction in consecutive cost accumulation. As a consequence horizontal costs are stabilized which improves the robustness of the matching result. We demonstrate the superiority of this iterative integration concept against a standard configuration of semi-global matching and compare our results to current state-of-the-art methods on the KITTI Vision Benchmark Suite. {\textcopyright} 2013 Springer-Verlag.},
author = {Hermann, Simon and Klette, Reinhard},
doi = {10.1007/978-3-642-37431-9_36},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/sgm{\_}driver{\_}assistance.pdf:pdf},
isbn = {9783642374302},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 3},
pages = {465--478},
title = {{Iterative semi-global matching for robust driver assistance systems}},
volume = {7726 LNCS},
year = {2013}
}
@article{Menze2015,
abstract = {This paper proposes a novel model and dataset for 3D scene flow estimation with an application to autonomous driving. Taking advantage of the fact that outdoor scenes often decompose into a small number of independently moving objects, we represent each element in the scene by its rigid motion parameters and each superpixel by a 3D plane as well as an index to the corresponding object. This minimal representation increases robustness and leads to a discrete-continuous CRF where the data term decomposes into pairwise potentials between superpixels and objects. Moreover, our model intrinsically segments the scene into its constituting dynamic components. We demonstrate the performance of our model on existing benchmarks as well as a novel realistic dataset with scene flow ground truth. We obtain this dataset by annotating 400 dynamic scenes from the KITTI raw data collection using detailed 3D CAD models for all vehicles in motion. Our experiments also reveal novel challenges which cannot be handled by existing methods.},
author = {Menze, Moritz and Geiger, Andreas},
doi = {10.1109/CVPR.2015.7298925},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Menze{\_}Object{\_}Scene{\_}Flow{\_}2015{\_}CVPR{\_}paper.pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {3061--3070},
title = {{Object scene flow for autonomous vehicles}},
volume = {07-12-June},
year = {2015}
}
@article{Poggi2017,
abstract = {Confidence measures aim at detecting unreliable depth measurements and play an important role for many purposes and in particular, as recently shown, to improve stereo accuracy. This topic has been thoroughly investigated by Hu and Mordohai in 2010 (and 2012) considering 17 confidence measures and two local algorithms on the two datasets available at that time. However, since then major breakthroughs happened in this field: the availability of much larger and challenging datasets, novel and more effective stereo algorithms including ones based on deep learning and confidence measures leveraging on machine learning techniques. Therefore, this paper aims at providing an exhaustive and updated review and quantitative evaluation of 52 (actually, 76 considering variants) stateof- the-art confidence measures - focusing on recent ones mostly based on random-forests and deep learning - with three algorithms on the challenging datasets available today. Moreover we deal with problems inherently induced by learning-based confidence measures. How are these methods able to generalize to new data? How a specific training improves their effectiveness? How more effective confidence measures can actually improve the overall stereo accurac?},
author = {Poggi, Matteo and Tosi, Fabio and Mattoccia, Stefano},
doi = {10.1109/ICCV.2017.559},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Poggi, Tosi, Mattoccia - 2017 - Quantitative Evaluation of Confidence Measures in a Machine Learning World.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {5238--5247},
title = {{Quantitative Evaluation of Confidence Measures in a Machine Learning World}},
volume = {2017-Octob},
year = {2017}
}
@article{Viola1995,
author = {Viola, Paul A},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/AITR-1548.pdf:pdf},
journal = {Artificial Intelligence},
number = {1548},
title = {{MASSACHUSETTS INSTITUTE OF TECHNOLOGY Alignment by Maximization of Mutual Information}},
year = {1995}
}
@article{Geiger2011,
abstract = {In this paper we propose a novel approach to binocular stereo for fast matching of high-resolution images. Our approach builds a prior on the disparities by forming a triangulation on a set of support points which can be robustly matched, reducing the matching ambiguities of the remaining points. This allows for efficient exploitation of the disparity search space, yielding accurate dense reconstruction without the need for global optimization. Moreover, our method automatically determines the disparity range and can be easily parallelized. We demonstrate the effectiveness of our approach on the large-scale Middlebury benchmark, and show that state-of-the-art performance can be achieved with significant speedups. Computing the left and right disparity maps for a one Megapixel image pair takes about one second on a single CPU core. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
author = {Geiger, Andreas and Roser, Martin and Urtasun, Raquel},
doi = {10.1007/978-3-642-19315-6_3},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Geiger2010ACCV.pdf:pdf},
isbn = {9783642193149},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 1},
pages = {25--38},
title = {{Efficient large-scale stereo matching}},
volume = {6492 LNCS},
year = {2011}
}
@article{Bleyer2005,
abstract = {This work describes a stereo algorithm that takes advantage of image segmentation, assuming that disparity varies smoothly inside a segment of homogeneous colour and depth discontinuities coincide with segment borders. Image segmentation allows our method to generate correct disparity estimates in large untextured regions and precisely localize depth boundaries. The disparity inside a segment is represented by a planar equation. To derive the plane model, an initial disparity map is generated. We use a window-based approach that exploits the results of segmentation. The size of the match window is chosen adaptively. A segment's planar model is then derived by robust least squared error fitting using the initial disparity map. In a layer extraction step, disparity segments that are found to be similar according to a plane dissimilarity measurement are combined to form a single robust layer. We apply a modified mean-shift algorithm to extract clusters of similar disparity segments. Segments of the same cluster build a layer, the plane parameters of which are computed from its spatial extent using the initial disparity map. We then optimize the assignment of segments to layers using a global cost function. The quality of the disparity map is measured by warping the reference image to the second view and comparing it with the real image. Z-buffering enforces visibility and allows the explicit detection of occlusions. The cost function measures the colour dissimilarity between the warped and real views, and penalizes occlusions and neighbouring segments that are assigned to different layers. Since the problem of finding the assignment of segments to layers that minimizes this cost function is N P-complete, an efficient greedy algorithm is applied to find a local minimum. Layer extraction and assignment are alternately applied. Qualitative and quantitative results obtained for benchmark image pairs show that the proposed algorithm outperforms most state-of-the-art matching algorithms currently listed on the Middlebury stereo evaluation website. The technique achieves particularly good results in areas with depth discontinuities and related occlusions, where missing stereo information is substituted from surrounding regions. Furthermore, we apply the algorithm to a self-recorded image set and show 3D visualizations of the derived results. {\textcopyright} 2005 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.},
author = {Bleyer, Michael and Gelautz, Margrit},
doi = {10.1016/j.isprsjprs.2005.02.008},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/10.1.1.218.7501.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Clustering,Colour segmentation,Image warping,Layered stereo,Stereo matching},
number = {3},
pages = {128--150},
title = {{A layered stereo matching algorithm using image segmentation and global visibility constraints}},
volume = {59},
year = {2005}
}
@article{Zabih1994,
abstract = {We propose a new approach to the correspondence problem that makes use of non-parametric local transforms as the basis for correlation. Non-parametric local transforms rely on the relative ordering of local intensity values, and not on the intensity values themselves. Correlation using such transforms can tolerate a significant number of outliers. This can result in improved performance near object boundaries when compared with conventional methods such as normalized correlation. We introduce two non-parametric local transforms: the rank transform, which measures local intensity, and the census transform, which summarizes local image structure. We describe some properties of these transforms, and demonstrate their utility on both synthetic and real data.},
author = {Zabih, Ramin and Woodfill, John},
doi = {10.1007/bfb0028345},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zabih, Woodfill - 1994 - Non-parametric local transforms for computing visual correspondence.pdf:pdf},
isbn = {9783540579571},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {151--158},
title = {{Non-parametric local transforms for computing visual correspondence}},
volume = {801 LNCS},
year = {1994}
}
@article{JointCommitteeForGuidesInMetrology2008,
abstract = {When reporting the result of a measurement of a physical quantity, some quantitative indication of the result has to be given to assess its reliability and to allow comparisons to be made. The Guide to the expression of uncertainty in measurement establishes general rules for evaluating and expressing uncertainty in measurement that can be followed at many levels of accuracy and in many fields.},
author = {{Joint Committee For Guides In Metrology}},
doi = {10.1373/clinchem.2003.030528},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Joint Committee For Guides In Metrology - 2008 - Evaluation of measurement data — Guide to the expression of uncertainty in measurement.pdf:pdf},
isbn = {9267101889},
issn = {00099147},
journal = {International Organization for Standardization Geneva ISBN},
keywords = {GUM Guide to the expression of uncertainty in meas},
number = {September},
pages = {134},
pmid = {15105367},
title = {{Evaluation of measurement data — Guide to the expression of uncertainty in measurement}},
url = {http://www.bipm.org/en/publications/guides/gum.html},
volume = {50},
year = {2008}
}
@article{Scharstein2014,
abstract = {We present a structured lighting system for creating highresolution stereo datasets of static indoor scenes with highly accurate ground-truth disparities. The system includes novel techniques for efficient 2D subpixel correspondence search and self-calibration of cameras and projectors with modeling of lens distortion. Combining disparity estimates from multiple projector positions we are able to achieve a disparity accuracy of 0.2 pixels on most observed surfaces, including in halfoccluded regions. We contribute 33 new 6-megapixel datasets obtained with our system and demonstrate that they present new challenges for the next generation of stereo algorithms.},
author = {Scharstein, Daniel and Hirschm{\"{u}}ller, Heiko and Kitajima, York and Krathwohl, Greg and Ne{\v{s}}i{\'{c}}, Nera and Wang, X. and Westling, Porter},
doi = {10.1007/978-3-319-11752-2_3},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/high{\_}resolution{\_}stereo.pdf:pdf},
isbn = {9783319117515},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {1},
pages = {31--42},
title = {{High-resolution stereo datasets with subpixel-accurate ground truth}},
volume = {8753},
year = {2014}
}
@article{Klaus2006,
abstract = {A novel stereo matching algorithm is proposed that utilizes color segmentation on the reference image and a self-adapting matching score that maximizes the number of reliable correspondences. The scene structure is modeled by a set of planar surface patches which are estimated using a new technique that is more robust to outliers. Instead of assigning a disparity value to each pixel, a disparity plane is assigned to each segment. The optimal disparity plane labeling is approximated by applying belief propagation. Experimental results using the Middlebury stereo test bed demonstrate the superior performance of the proposed method. {\textcopyright} 2006 IEEE.},
author = {Klaus, Andreas and Sormann, Mario and Karner, Konrad},
doi = {10.1109/ICPR.2006.1033},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Segment-Based{\_}Stereo{\_}Matching{\_}Using{\_}Belief{\_}Propaga.pdf:pdf},
isbn = {0769525210},
issn = {10514651},
journal = {Proceedings - International Conference on Pattern Recognition},
pages = {15--18},
title = {{Segment-based stereo matching using belief propagation and a self-adapting dissimilarity measure}},
volume = {3},
year = {2006}
}
@article{Haralick1987,
abstract = {For the purposes of object or defect identification required in industrial vision applications, the operations of mathematical morphology are more useful than the convolution operations employed in signal processing because the morphological operators relate directly to shape. The tutorial provided in this paper reviews both binary morphology and gray scale morphology, covering the operations of dilation, erosion, opening, and closing and their relations. Examples are given for each morphological concept and explanations are given for many of their interrelationships. Copyright {\textcopyright} 1987 by The Institute of Electrical and Electronics Engineers, Inc.},
author = {Haralick, Robert M. and Sternberg, Stanley R. and Zhuang, Xinhua},
doi = {10.1109/TPAMI.1987.4767941},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/04767941.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Closing,dilation,erosion,filtering,image analysis,morphology,opening,shape analysis},
number = {4},
pages = {532--550},
pmid = {21869411},
title = {{Image Analysis Using Mathematical Morphology}},
volume = {PAMI-9},
year = {1987}
}
@misc{Hartley2011,
author = {Hartley, Richard and Zisserman, Andrew},
booktitle = {Multiple View Geometry in Computer Vision},
doi = {10.1017/cbo9780511811685.006},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/HZ2eCh2.pdf:pdf},
pages = {65--86},
title = {{Projective Geometry and Transformations of 3D}},
year = {2011}
}
@article{Hu2012,
abstract = {We present an extensive evaluation of 17 confidence measures for stereo matching that compares the most widely used measures as well as several novel techniques proposed here. We begin by categorizing these methods according to which aspects of stereo cost estimation they take into account and then assess their strengths and weaknesses. The evaluation is conducted using a winner-take-all framework on binocular and multibaseline datasets with ground truth. It measures the capability of each confidence method to rank depth estimates according to their likelihood for being correct, to detect occluded pixels, and to generate low-error depth maps by selecting among multiple hypotheses for each pixel. Our work was motivated by the observation that such an evaluation is missing from the rapidly maturing stereo literature and that our findings would be helpful to researchers in binocular and multiview stereo. {\textcopyright} 2012 IEEE.},
author = {Hu, Xiaoyan and Mordohai, Philippos},
doi = {10.1109/TPAMI.2012.46},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/10.1.1.295.5787.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {3D reconstruction,Stereo vision,confidence,correspondence,distinctiveness},
number = {11},
pages = {2121--2133},
title = {{A quantitative evaluation of confidence measures for stereo vision}},
volume = {34},
year = {2012}
}
@article{Luo,
abstract = {In the past year, convolutional neural networks have been shown to perform extremely well for stereo estimation. However, current architectures rely on siamese networks which exploit concatenation followed by further processing layers, requiring a minute of GPU computation per image pair. In contrast, in this paper we propose a matching network which is able to produce very accurate results in less than a second of GPU computation. Towards this goal, we exploit a product layer which simply computes the inner product between the two representations of a siamese architecture. We train our network by treating the problem as multi-class classification, where the classes are all possible disparities. This allows us to get calibrated scores, which result in much better matching performance when compared to existing approaches.},
author = {Luo, Wenjie and Schwing, Alexander G},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Luo{\_}Efficient{\_}Deep{\_}Learning{\_}CVPR{\_}2016{\_}paper.pdf:pdf},
title = {{(Michael recom)Efficient Deep Learning for Stereo Matching}},
url = {http://www.cs.toronto.edu/}
}
@article{DAngelo2016,
abstract = {Digital elevation models are one of the basic products that can be generated from remotely sensed imagery. The Semi Global Matching (SGM) algorithm is a robust and practical algorithm for dense image matching. The connection between SGM and Belief Propagation was recently developed, and based on that improvements such as correction of over-counting the data term, and a new confidence measure have been proposed. Later the MGM algorithm has been proposed, it aims at improving the regularization step of SGM, but has only been evaluated on the Middlebury stereo benchmark so far. This paper evaluates these proposed improvements on the ISPRS satellite stereo benchmark, using a Pleiades Triplet and a Cartosat-1 Stereo pair. The over-counting correction slightly improves matching density, at the expense of adding a few outliers. The MGM cost aggregation shows leads to a slight increase of accuracy.},
author = {D'Angelo, Pablo},
doi = {10.5194/isprsarchives-XLI-B1-299-2016},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/D'Angelo - 2016 - Improving semi-global matching Cost aggregation and confidence measure.pdf:pdf},
issn = {16821750},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Accuracy,Benchmark,Dense matching,Digital elevation model,Stereo},
number = {July},
pages = {299--304},
title = {{Improving semi-global matching: Cost aggregation and confidence measure}},
volume = {2016-Janua},
year = {2016}
}
@article{Seki2017,
abstract = {This paper deals with deep neural networks for predicting accurate dense disparity map with Semi-global matching (SGM). SGM is a widely used regularization method for real scenes because of its high accuracy and fast computation speed. Even though SGM can obtain accurate results, tuning of SGM's penalty-parameters, which control a smoothness and discontinuity of a disparity map, is uneasy and empirical methods have been proposed. We propose a learning based penalties estimation method, which we call SGM-Nets that consist of Convolutional Neural Networks. A small image patch and its position are input into SGM-Nets to predict the penalties for the 3D object structures. In order to train the networks, we introduce a novel loss function which is able to use sparsely annotated disparity maps such as captured by a LiDAR sensor in real environments. Moreover, we propose a novel SGM parameterization, which deploys different penalties depending on either positive or negative disparity changes in order to represent the object structures more discriminatively. Our SGM-Nets outperformed state of the art accuracy on KITTI benchmark datasets.},
author = {Seki, Akihito and Pollefeys, Marc and Corporation, Toshiba and Z{\"{u}}rich, E. T.H. and Microsoft},
doi = {10.1109/CVPR.2017.703},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Seki et al. - 2017 - SGM-Nets Semi-global matching with neural networks.pdf:pdf},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
number = {1},
pages = {6640--6649},
title = {{SGM-Nets: Semi-global matching with neural networks}},
volume = {2017-Janua},
year = {2017}
}
@article{Zbontar2015,
abstract = {We present a method for extracting depth information from a rectified image pair. We train a convolutional neural network to predict how well two image patches match and use it to compute the stereo matching cost. The cost is refined by cross-based cost aggregation and semiglobal matching, followed by a left-right consistency check to eliminate errors in the occluded regions. Our stereo method achieves an error rate of 2.61{\%} on the KITTI stereo dataset and is currently (August 2014) the top performing method on this dataset.},
archivePrefix = {arXiv},
arxivId = {1409.4326},
author = {{\v{Z}}bontar, Jure and {Le Cun}, Yann},
doi = {10.1109/CVPR.2015.7298767},
eprint = {1409.4326},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Zbontar{\_}Computing{\_}the{\_}Stereo{\_}2015{\_}CVPR{\_}paper.pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
number = {1},
pages = {1592--1599},
title = {{Computing the stereo matching cost with a convolutional neural network}},
volume = {07-12-June},
year = {2015}
}
@article{Taguchi2008,
abstract = {We present an over-segmentation based, dense stereo algorithm that jointly estimates segmentation and depth. For mixed pixels on segment boundaries, the algorithm computes foreground opacity (alpha), as well as color and depth for the foreground and background. We model the scene as a collection of fronto-parallel planar segments in a reference view, and use a generative model for image formation that handles mixed pixels at segment boundaries. Our method iteratively updates the segmentation based on color, depth and shape constraints using MAP estimation. Given a segmentation, the depth estimates are updated using belief propagation. We show that our method is competitive with the state-of-the-art based on the new Middlebury stereo evaluation, and that it overcomes limitations of traditional segmentation based methods while properly handling mixed pixels. Z-keying results show the advantages of combining opacity and depth estimation. {\textcopyright}2008 IEEE.},
author = {Taguchi, Yuichi and Wilburn, Bennett and Zitnick, C. Lawrence},
doi = {10.1109/CVPR.2008.4587691},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/08CVPR{\_}StereoMixedPixels.pdf:pdf},
isbn = {9781424422432},
journal = {26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR},
title = {{Stereo reconstruction with mixed pixels using adaptive over-segmentation}},
year = {2008}
}
@article{Hirschmuller2008,
abstract = {This paper describes the Semi-Global Matching (SGM) stereo method. It uses a pixelwise, Mutual Information based matching cost for compensating radiometric differences of input images. Pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. SGM performs a fast approximation by pathwise optimizations from all directions. The discussion also addresses occlusion detection, subpixel refinement and multi-baseline matching. Additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments and the interpolation of gaps are presented. Finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed.A comparison on standard stereo images shows that SGM is among the currently top-ranked algorithms and is best, if subpixel accuracy is considered. The complexity is linear to the number of pixels and disparity range, which results in a runtime of just 1-2s on typical test images. An in depth evaluation of the Mutual Information based matching cost demonstrates a tolerance against a wide range of radiometric transformations. Finally, examples of reconstructions from huge aerial frame and pushbroom images demonstrate that the presented ideas are working well on practical problems. {\textcopyright} 2008 IEEE.},
author = {Hirschm{\"{u}}ller, Heiko},
doi = {10.1109/TPAMI.2007.1166},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/semi{\_}global{\_}01.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Global optimization,Multibaseline,Mutual information,Stereo},
number = {2},
pages = {328--341},
title = {{Stereo processing by semiglobal matching and mutual information}},
volume = {30},
year = {2008}
}
@book{Gries2010,
abstract = {Na.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Gries, David and Schneider, Fred B},
booktitle = {Media},
doi = {10.1007/978-1-84882-256-6},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Computer{\_}vision/Texts{\_}in{\_}Computer{\_}Science{\_}Richard.pdf:pdf},
isbn = {9781848829343},
issn = {02569574},
pages = {823},
pmid = {20529422},
title = {{Texts in Computer Science}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20549881},
volume = {42},
year = {2010}
}
@article{Demetz2013,
abstract = {Most researchers agree that invariances are desirable in computer vision systems. However, one always has to keep in mind that this is at the expense of accuracy: By construction, all invariances inevitably discard information. The concept of morphological invariance is a good example for this trade-off and will be in the focus of this paper. Our goal is to develop a descriptor of local image structure that carries the maximally possible amount of local image information under this invariance. To fulfill this requirement, our descriptor has to encode the full ordering of the pixel intensities in the local neighbourhood. As a solution, we introduce the complete rank transform, which stores the intensity rank of every pixel in the local patch. As a proof of concept, we embed our novel descriptor in a prototypical TVL1-type energy functional for optical flow computation, which we minimise with a traditional coarse-to-fine warping scheme. In this straightforward framework, we demonstrate that our descriptor is preferable over related features that exhibit the same invariance. Finally, we show by means of public benchmark systems that our method produces - in spite of its simplicity - results of competitive quality.},
author = {Demetz, Oliver and Hafner, David and Weickert, Joachim},
doi = {10.5244/C.27.50},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/rank{\_}transform.pdf:pdf},
journal = {BMVC 2013 - Electronic Proceedings of the British Machine Vision Conference 2013},
title = {{The complete rank transform: A tool for accurate and morphologically invariant matching of structures}},
year = {2013}
}
@article{Dougherty2009,
author = {Dougherty, Edward R. and Lotufo, Roberto A.},
doi = {10.1117/3.501104.ch2},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/TT59.pdf:pdf},
journal = {Hands-on Morphological Image Processing},
pages = {25--44},
title = {{Binary Opening and Closing}},
volume = {25},
year = {2009}
}
@misc{Freeman1991,
abstract = {Oriented filters are useful in many early vision and image processing tasks. One often needs to apply the same filter, rotated to different angles under adaptive control, or wishes to calculate the filter response at various orientations. We present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively “steer” a filter to any orientation, and to determine analytically the filter output as a function of orientation. Steerable filters may be designed in quadrature pairs to allow adaptive control over phase as well as orientation. We show how to design and steer the filters and present examples of their use in several tasks: the analysis of orientation and phase, angularly adaptive filtering, edge detection, and shape from shading. One can also build a self-similar steerable pyramid representation. The same concepts can be generalized to the design of 3-D steerable filters, which should be useful in the analysis of image sequences and volumetric data. {\textcopyright} 1991, IEEE. All rights reserved.},
author = {Freeman, William T. and Adelson, Edward H.},
booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
doi = {10.1109/34.93808},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/steerpaper91FreemanAdelson.pdf:pdf},
issn = {01628828},
keywords = {Early vision,edge detection,filter design image analysis,orientation analysis,oriented filters,shape from shading,texture analysis wavelets},
number = {9},
pages = {891--906},
title = {{The Design and Use of Steerable Filters}},
volume = {13},
year = {1991}
}
@article{Poggi2019,
abstract = {Stereo is a prominent technique to infer dense depth maps from images, and deep learning further pushed forward the state-of-the-art, making end-to-end architectures unrivaled when enough data is available for training. However, deep networks suffer from significant drops in accuracy when dealing with new environments. Therefore, in this paper, we introduce Guided Stereo Matching, a novel paradigm leveraging a small amount of sparse, yet reliable depth measurements retrieved from an external source enabling to ameliorate this weakness. The additional sparse cues required by our method can be obtained with any strategy (e.g., a LiDAR) and used to enhance features linked to corresponding disparity hypotheses. Our formulation is general and fully differentiable, thus enabling to exploit the additional sparse inputs in pre-trained deep stereo networks as well as for training a new instance from scratch. Extensive experiments on three standard datasets and two state-of-the-art deep architectures show that even with a small set of sparse input cues, i) the proposed paradigm enables significant improvements to pre-trained networks. Moreover, ii) training from scratch notably increases accuracy and robustness to domain shifts. Finally, iii) it is suited and effective even with traditional stereo algorithms such as SGM.},
archivePrefix = {arXiv},
arxivId = {1905.10107},
author = {Poggi, Matteo and Pallotti, Davide and Tosi, Fabio and Mattoccia, Stefano},
eprint = {1905.10107},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Poggi et al. - 2019 - Guided Stereo Matching.pdf:pdf},
title = {{Guided Stereo Matching}},
url = {http://arxiv.org/abs/1905.10107},
year = {2019}
}
@article{Kim2003,
abstract = {We address visual correspondence problems without assuming that scene points have similar intensities in different views. This situation is common, usually due tonon-lambertian scenes or to differences between cameras. We use maximization of mutual information, apowerful technique for registering images that requiresno apriori model of the relationship between scene intensities in different views. However, it has provendifficult to use mutual information to compute densevisual correspondence. Comparing fixed-size windowsvia mutual information suffers from the well-knownproblems of fixed windows, namely poor performanceat discontinuities and in low-texture regions. In thispaper, we show how to compute visual correspondenceusing mutual information without suffering from theseproblems. Using a simple approximation, mutual information can be incorporated into the standard energyminimization framework used in early vision. The energy can then be efficiently minimized using graph cuts,which preserve discontinuities and handle low-textureregions. The resulting algorithm combines the accuratedisparity maps that come from graph cuts with the tolerance for intensity changes that comes from mutual information.},
author = {Kim, Junhwan and Kolmogorov, Vladimir and Zabih, Ramin},
doi = {10.1109/ICCV.2003.1238463},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Visual{\_}correspondence{\_}using{\_}energy{\_}minim.pdf:pdf},
isbn = {0769519504},
journal = {Proceedings of the Ninth IEEE International Conference on Computer Vision},
number = {Iccv},
pages = {1033--1040},
title = {{Energy Minimization and Mutual Information}},
year = {2003}
}
@book{Abadi2005,
author = {Abadi, Mart{\'{i}}n and {De Alfaro}, Luca},
booktitle = {Lecture Notes in Computer Science},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abadi, De Alfaro - 2005 - Lecture Notes in Computer Science Preface.pdf:pdf},
isbn = {9783642046667},
issn = {03029743},
title = {{Lecture Notes in Computer Science: Preface}},
volume = {3653},
year = {2005}
}
@article{Spangenberg2014,
abstract = {Semi-Global Matching (SGM) is widely used for real-time stereo vision in the automotive context. Despite its popularity, only implementations using reconfigurable hardware (FPGA) or graphics hardware (GPU) achieve high enough frame rates for intelligent vehicles. Existing real-time implementations for general purpose PCs use image and disparity sub-sampling at the expense of matching quality. We study methods to improve the efficiency of SGM on general purpose PCs, through fine grained parallelization and usage of multiple cores. The different approaches are evaluated on the KITTI benchmark, which provides real imagery with LIDAR ground truth. The system is able to compute disparity maps of VGA image pairs with a disparity range of 128 values at more than 16 Hz. The approach is scalable to the number of available cores and portable to embedded processors. {\textcopyright} 2014 IEEE.},
author = {Spangenberg, Robert and Langner, Tobias and Adfeldt, Sven and Rojas, Raul},
doi = {10.1109/IVS.2014.6856419},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Semi-Global-Matching.pdf:pdf},
isbn = {9781479936380},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
pages = {195--201},
title = {{Large scale Semi-Global Matching on the CPU}},
year = {2014}
}
@article{Maragos,
author = {Maragos, Petros},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/6b0e4a0a6fed80e1fa4ac5055c89a3cd2aa4.pdf:pdf},
title = {{MORPHOLOGICAL ADVANCES IN MORPHOLOGICAL ON ADVANCES TUTORIAL ON ANALYSIS AND ANALYSIS Unified Image Algebra Unified}}
}
@article{Spyropoulos2014,
abstract = {While machine learning has been instrumental to the ongoing progress in most areas of computer vision, it has not been applied to the problem of stereo matching with similar frequency or success. We present a supervised learning approach for predicting the correctness of stereo matches based on a random forest and a set of features that capture various forms of information about each pixel. We show highly competitive results in predicting the correctness of matches and in confidence estimation, which allows us to rank pixels according to the reliability of their assigned disparities. Moreover, we show how these confidence values can be used to improve the accuracy of disparity maps by integrating them with an MRF-based stereo algorithm. This is an important distinction from current literature that has mainly focused on sparsification by removing potentially erroneous disparities to generate quasi-dense disparity maps.},
author = {Spyropoulos, Aristotle and Komodakis, Nikos and Mordohai, Philippos},
doi = {10.1109/CVPR.2014.210},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spyropoulos, Komodakis, Mordohai - 2014 - Learning to detect ground control points for improving the accuracy of stereo matching.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {3D computer vision,Stereo correspondence},
pages = {1621--1628},
publisher = {IEEE},
title = {{Learning to detect ground control points for improving the accuracy of stereo matching}},
volume = {i},
year = {2014}
}
@article{Scharstein2003,
abstract = {Recent progress in stereo algorithm performance is quickly outpacing the ability of existing stereo data sets to discriminate among the best-performing algorithms, motivating the need for more challenging scenes with accurate ground truth information. This paper describes a method for acquiring high-complexity stereo image pairs with pixel-accurate correspondence information using structured light. Unlike traditional range-sensing approaches, our method does not require the calibration of the light sources and yields registered disparity maps between all pairs of cameras and illumination projectors. We present new stereo data sets acquired with our method and demonstrate their suitability for stereo algorithm evaluation. Our results are available at http://www.middlebury.edu/stereo/.},
author = {Scharstein, Daniel and Szeliski, Richard},
doi = {10.1109/cvpr.2003.1211354},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/structured-light.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
title = {{High-accuracy stereo depth maps using structured light}},
volume = {1},
year = {2003}
}
@article{Zitnick2004,
abstract = {The ability to interactively control viewpoint while watching a video is an exciting application of image-based rendering. The goal of our work is to render dynamic scenes with interactive viewpoint control using a relatively small number of video cameras. In this paper, we show how high-quality video-based rendering of dynamic scenes can be accomplished using multiple synchronized video streams combined with novel image-based modeling and rendering algorithms. Once these video streams have been processed, we can synthesize any intermediate view between cameras at any time, with the potential for space-time manipulation. In our approach, we first use a novel color segmentation-based stereo algorithm to generate high-quality photoconsistent correspondences across all camera views. Mattes for areas near depth discontinuities are then automatically extracted to reduce artifacts during view synthesis. Finally, a novel temporal two-layer compressed representation that handles matting is developed for rendering at interactive rates. Copyright {\textcopyright} 2004 ACM.},
author = {Zitnick, C. Lawrence and Kang, Sing Bing and Uyttendaele, Matthew and Winder, Simon and Szeliski, Richard},
doi = {10.1145/1186562.1015766},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/1015706.1015766.pdf:pdf},
journal = {ACM SIGGRAPH 2004 Papers, SIGGRAPH 2004},
keywords = {Computer vision,Dynamic scenes,Image-based rendering},
number = {212},
pages = {600--608},
title = {{High-quality video view interpolation using a layered representation}},
volume = {1},
year = {2004}
}
@article{Chen2015,
author = {Chen, Zhuoyuan and Sun, Xun and Wang, Liang and Yu, Y and Huang, C},
doi = {10.1109/ICCV.2015.117},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Chen{\_}A{\_}Deep{\_}Visual{\_}ICCV{\_}2015{\_}paper.pdf:pdf},
journal = {2015 IEEE International Conference on Computer Vision (ICCV)},
keywords = {Computational modeling,Data models,Feature extraction,KITTI benchmark,Machine learning,Middlebury data sets,Neural networks,Training,Visualization,convolutional neural network,cross-validation results,data-driven matching cost,deep visual correspondence embedding model,embedding feature space,global stereo framework,ground truth disparities,image matching,image patches,labeled training set,neural nets,pixel dissimilarity measurement,stereo image processing,stereo images,stereo matching costs,visual similarity relationships},
number = {d},
pages = {1--9},
title = {{A Deep Visual Correspondence Embedding Model}},
year = {2015}
}
@article{Shimizu2002,
abstract = {Area-based matching and sub-pixel displacement estimation using similarity measures are common methods for various fields. Sub-pixel estimation using parabola fitting over three points with their similarity measures is also a common method to increase the resolution of matching. However, this estimation contains a systematic error depending on the image characteristics, the similarity function, and the fitting function used for the sub-pixel estimation. In this paper, the characteristics of sub-pixel estimation error have been clarified using a simple analysis model. Although this model is quite simple, it enables us to make a theoretical analysis for general images without assuming any specific image pattern. Through this analysis, it has been shown that there are the right combinations of the similarity functions and the fitting functions. Also, so-called "pixel-locking" effect, where the estimated positions tend to be biased toward integer values, has been explained. Finally, the analyses are verified with an experiment using real images.},
author = {Shimizu, Masao and Okutomi, Masatoshi},
doi = {10.1109/ICDSP.2002.1028317},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shimizu, Okutomi - 2002 - An analysis of sub-pixel estimation error on area-based image matching.pdf:pdf},
isbn = {0780375033},
journal = {International Conference on Digital Signal Processing, DSP},
pages = {1239--1242},
title = {{An analysis of sub-pixel estimation error on area-based image matching}},
volume = {2},
year = {2002}
}
@article{Gehrig2009,
abstract = {Many real-time stereo vision systems are available on low-power platforms. They all either use a local correlation-like stereo engine or perform dynamic programming variants on a scan-line. However, when looking at high-performance global stereo methods as listed in the upper third of the Middlebury database, the low-power real-time implementations for these methods are still missing. We propose a real-time implementation of the semi-global matching algorithm with algorithmic extensions for automotive applications on a reconfigurable hardware platform resulting in a low power consumption of under 3W. The algorithm runs at 25Hz processing image pairs of size 750x480 pixels and computing stereo on a 680x400 image part with up to a maximum of 128 disparities. {\textcopyright} 2009 Springer-Verlag Berlin Heidelberg.},
author = {Gehrig, Stefan K. and Eberli, Felix and Meyer, Thomas},
doi = {10.1007/978-3-642-04667-4_14},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/real{\_}time{\_}low{\_}power{\_}sgm.pdf:pdf},
isbn = {3642046665},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {134--143},
title = {{A real-time low-power stereo vision engine using semi-global matching}},
volume = {5815 LNCS},
year = {2009}
}
@article{Mostegel2016,
abstract = {Learned confidence measures gain increasing importance for outlier removal and quality improvement in stereo vision. However, acquiring the necessary training data is typically a tedious and time consuming task that involves manual interaction, active sensing devices and/or synthetic scenes. To overcome this problem, we propose a new, flexible, and scalable way for generating training data that only requires a set of stereo images as input. The key idea of our approach is to use different view points for reasoning about contradictions and consistencies between multiple depth maps generated with the same stereo algorithm. This enables us to generate a huge amount of training data in a fully automated manner. Among other experiments, we demonstrate the potential of our approach by boosting the performance of three learned confidence measures on the KITTI2012 dataset by simply training them on a vast amount of automatically generated training data rather than a limited amount of laser ground truth data.},
archivePrefix = {arXiv},
arxivId = {1604.05132},
author = {Mostegel, Christian and Rumpler, Markus and Fraundorfer, Friedrich and Bischof, Horst},
doi = {10.1109/CVPR.2016.441},
eprint = {1604.05132},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/Mostegel{\_}Using{\_}Self-Contradiction{\_}to{\_}CVPR{\_}2016{\_}paper.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {4067--4076},
title = {{Using Self-Contradiction to Learn Confidence Measures in Stereo Vision}},
volume = {2016-Decem},
year = {2016}
}
@article{Spangenberg2014a,
abstract = {Semi-Global Matching (SGM) is widely used for real-time stereo vision in the automotive context. Despite its popularity, only implementations using reconfigurable hardware (FPGA) or graphics hardware (GPU) achieve high enough frame rates for intelligent vehicles. Existing real-time implementations for general purpose PCs use image and disparity sub-sampling at the expense of matching quality. We study methods to improve the efficiency of SGM on general purpose PCs, through fine grained parallelization and usage of multiple cores. The different approaches are evaluated on the KITTI benchmark, which provides real imagery with LIDAR ground truth. The system is able to compute disparity maps of VGA image pairs with a disparity range of 128 values at more than 16 Hz. The approach is scalable to the number of available cores and portable to embedded processors. {\textcopyright} 2014 IEEE.},
author = {Spangenberg, Robert and Langner, Tobias and Adfeldt, Sven and Rojas, Raul},
doi = {10.1109/IVS.2014.6856419},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spangenberg et al. - 2014 - Large scale Semi-Global Matching on the CPU.pdf:pdf},
isbn = {9781479936380},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
number = {Iv},
pages = {195--201},
title = {{Large scale Semi-Global Matching on the CPU}},
year = {2014}
}
@article{Ko2017Ko2017,
abstract = {The census transform in computing the matching cost of stereo matching is simple and robust under luminance variations in stereo image pairs; however, different disparity maps are generated depending on the shape and size of the census transform window. In this paper, we propose a stereo matching method with variable sizes of census transform windows based on the gradients of stereo images. Our experiment shows higher accuracy of disparity values in the area of depth discontinuities.},
author = {Ko, Jaeryun and Ho, Yo Sung},
doi = {10.1109/APSIPA.2016.7820827},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ko, Ho - 2017 - Stereo matching using census transform of adaptive window sizes with gradient images.pdf:pdf},
isbn = {9789881476821},
journal = {2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA 2016},
pages = {2--5},
title = {{Stereo matching using census transform of adaptive window sizes with gradient images}},
year = {2017}
}
@article{Hernandez-Juarez2016,
abstract = {Dense, robust and real-time computation of depth information from stereo-camera systems is a computationally demanding requirement for robotics, advanced driver assistance systems (ADAS) and autonomous vehicles. Semi-Global Matching (SGM) is a widely used algorithm that propagates consistency constraints along several paths across the image. This work presents a real-time system producing reliable disparity estimation results on the new embedded energye cient GPU devices. Our design runs on a Tegra X1 at 42 frames per second (fps) for an image size of 640 480, 128 disparity levels, and using 4 path directions for the SGM method.},
archivePrefix = {arXiv},
arxivId = {1610.04121},
author = {Hernandez-Juarez, D. and Chacon, A. and Espinosa, A. and Vazquez, D. and Moure, J. C. and Lopez, A. M.},
doi = {10.1016/j.procs.2016.05.305},
eprint = {1610.04121},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/semi{\_}global{\_}02.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Autonomous driving,CUDA,Computer vision,Drive PX,Embedded systems,GPU,Semi-global matching,Stereo},
pages = {143--153},
title = {{Embedded real-time stereo estimation via Semi-Global Matching on the GPU}},
volume = {80},
year = {2016}
}
@article{Geiger2013,
abstract = {We present a novel dataset captured from a VW station wagon for use in mobile robotics and autonomous driving research. In total, we recorded 6 hours of traffic scenarios at 10-100 Hz using a variety of sensor modalities such as high-resolution color and grayscale stereo cameras, a Velodyne 3D laser scanner and a high-precision GPS/IMU inertial navigation system. The scenarios are diverse, capturing real-world traffic situations, and range from freeways over rural areas to inner-city scenes with many static and dynamic objects. Our data is calibrated, synchronized and timestamped, and we provide the rectified and raw image sequences. Our dataset also contains object labels in the form of 3D tracklets, and we provide online benchmarks for stereo, optical flow, object detection and other tasks. This paper describes our recording platform, the data format and the utilities that we provide. {\textcopyright} The Author(s) 2013.},
author = {Geiger, A. and Lenz, P. and Stiller, C. and Urtasun, R.},
doi = {10.1177/0278364913491297},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/0278364913491297.pdf:pdf},
issn = {02783649},
journal = {International Journal of Robotics Research},
keywords = {Dataset,GPS,KITTI,SLAM,autonomous driving,benchmarks,cameras,computer vision,field robotics,laser,mobile robotics,object detection,optical flow,stereo,tracking},
number = {11},
pages = {1231--1237},
title = {{Vision meets robotics: The KITTI dataset}},
volume = {32},
year = {2013}
}
@article{Tonioni2020,
abstract = {Deep convolutional neural networks trained end-to-end are the state-of-the-art methods to regress dense disparity maps from stereo pairs. These models, however, suffer from a notable decrease in accuracy when exposed to scenarios significantly different from the training set, e.g., real vs synthetic images, etc.). We argue that it is extremely unlikely to gather enough samples to achieve effective training/tuning in any target domain, thus making this setup impractical for many applications. Instead, we propose to perform unsupervised and continuous online adaptation of a deep stereo network, which allows for preserving its accuracy in any environment. However, this strategy is extremely computationally demanding and thus prevents real-time inference. We address this issue introducing a new lightweight, yet effective, deep stereo architecture, Modularly ADaptive Network (MADNet) and developing a Modular ADaptation (MAD) algorithm, which independently trains sub-portions of the network. By deploying MADNet together with MAD we introduce the first real-time self-adaptive deep stereo system enabling competitive performance on heterogeneous datasets.},
archivePrefix = {arXiv},
arxivId = {1810.05424},
author = {Tonioni, Alessio and Tosi, Fabio and Poggi, Matteo and Mattoccia, Stefano and Stefano, Luigi Di},
doi = {10.1109/cvpr.2019.00028},
eprint = {1810.05424},
file = {:C$\backslash$:/Users/jlosi/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tonioni et al. - 2020 - Real-Time Self-Adaptive Deep Stereo.pdf:pdf},
pages = {195--204},
title = {{Real-Time Self-Adaptive Deep Stereo}},
year = {2020}
}
@article{Kolmogorov2001,
abstract = {Several new algorithms for visual correspondence based on graph cuts [7, 14, 17] have recently been developed. While these methods give very strong results in practice, they do not handle occlusions properly. Specifically, they treat the two input images asymmetrically, and they do not ensure that a pixel corresponds to at most one pixel in the other image. In this paper, we present a new method which properly addresses occlusions, while preserving the advantages of graph cut algorithms. We give experimental results for stereo as well as motion, which demonstrate that our method performs well both at detecting occlusions and computing disparities.},
author = {Kolmogorov, V. and Zabih, R.},
doi = {10.1109/iccv.2001.937668},
file = {:C$\backslash$:/Users/jlosi/Documents/Aalto{\_}Uni/Master{\_}thesis/papers/2001-1838.pdf:pdf},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {508--515},
title = {{Computing visual correspondence with occlusions using graph cuts}},
volume = {2},
year = {2001}
}
